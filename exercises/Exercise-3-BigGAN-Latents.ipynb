{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC160 Data Science and the Arts - Twomey - Spring 2020 - [dsc160.roberttwomey.com](http://dsc160.roberttwomey.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLOYL1PJAAtK"
   },
   "source": [
    "# BigGAN Hands-On\n",
    "\n",
    "[BigGAN](https://arxiv.org/abs/1809.11096) set a standard for high resolution, high fidelity image synthesis in 2018. It contained four times as many parameters and eight times the batch size fo previous models, and synthesized a state of the art 512 x 512 images across 1000 different classes from Imagenet. It was also prohibitively expensive to train! Thankfully Google has released a number of pretrained models for us to explore. \n",
    "\n",
    "This exercise walks you through the use of the BigGAN network as a way to explore the role of latent vectors in generative output, and to build your familiarity with GANs and image synthesis. \n",
    "\n",
    "Compared to previous homeworks, this is less about the extension and more about hands one with GAN generation.\n",
    "\n",
    "- Part 1 - Exploration (75 points total)\n",
    "  - [A. Generate an Image](#1A.-Generate-One-Sample-Image)\n",
    "  - [B. Generate a set of Images](#1B.-Generate-a-Set-of-Images) (20 points)\n",
    "  - [C. Breeding Two Classes](#1C.-Breeding-Two-Classes) (15 points)\n",
    "  - [D. Interpolation](#1D.-Interpolation) (30 points)\n",
    "  - [E. Class Inversion](#1E.-Class-Inversion) (10 points)\n",
    "- Part 2 - Extension (25 points total)\n",
    "  - [A. Code](#2A.-Code) (15 points)\n",
    "  - [B. Discussion](#2B.-Discussion) (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJrTM6hAi0CJ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one time to install tensorflow-hub. This module allows us to download [models shared through tfhub](https://tfhub.dev/s?subtype=module,placeholder), including the BigGAN variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-hub --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lOZnst2jeWDL",
    "outputId": "8dcc1d63-0885-4c89-cdc8-bba1854e2683"
   },
   "outputs": [],
   "source": [
    "from io import StringIO, BytesIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from scipy.stats import truncnorm\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XS1_N6hKj8cz"
   },
   "source": [
    "## Get BigGAN Set Up\n",
    "\n",
    "First, set the module path.\n",
    "By default, we load the BigGAN-deep generator for 256x256 images from `https://tfhub.dev/deepmind/biggan-deep-256/1`.\n",
    "To generate 128x128 or 512x512 images or to use the original BigGAN generators, comment out the active `module_path` setting and uncomment one of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJCIhQPClKJ1"
   },
   "outputs": [],
   "source": [
    "# BigGAN-deep models\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-deep-128/1'  # 128x128 BigGAN-deep\n",
    "module_path = 'https://tfhub.dev/deepmind/biggan-deep-256/1'  # 256x256 BigGAN-deep\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-deep-512/1'  # 512x512 BigGAN-deep\n",
    "\n",
    "# BigGAN (original) models\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-128/2'  # 128x128 BigGAN\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-256/2'  # 256x256 BigGAN\n",
    "# module_path = 'https://tfhub.dev/deepmind/biggan-512/2'  # 512x512 BigGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stWb21nlcyCm"
   },
   "source": [
    "Download the pre-trained BigGAN generator module from TF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "tVgwgJiCH3PV",
    "outputId": "fc4946c3-4a9c-45d8-a632-30c1f8a367e3"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "print('Loading BigGAN module from:', module_path)\n",
    "module = hub.Module(module_path)\n",
    "inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)\n",
    "          for k, v in module.get_input_info_dict().items()}\n",
    "output = module(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining BigGAN model inputs and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some information about the model. What are its inputs and outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Inputs:\\n', '\\n'.join('\\t{}: {}'.format(*kv) for kv in inputs.items()))\n",
    "print('\\nOutput:', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z$ input is the noise vector (values drawn from a trunacted normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_z = inputs['z']\n",
    "input_z.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_z = input_z.shape.as_list()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$ is the class conditioning vector (one hot), across 1000 classes. You can see the available classes [here](https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_y = inputs['y']\n",
    "input_y.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the truncation allows you to set a tradeoff between individual sample quality and overall sample variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_trunc = inputs['truncation']\n",
    "input_trunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCeCg3Sdf8Nv"
   },
   "source": [
    "Create a TensorFlow session and initialize variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYJor5bOaVn1"
   },
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a helper function to display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, format='png', jpeg_fallback=True):\n",
    "    a = np.asarray(a, dtype=np.uint8)\n",
    "    #   str_file = StringIO()\n",
    "    str_file = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(str_file, format)\n",
    "    im_data = str_file.getvalue()\n",
    "    try:\n",
    "        disp = IPython.display.display(IPython.display.Image(im_data))\n",
    "    except IOError:\n",
    "        if jpeg_fallback and format != 'jpeg':\n",
    "            print ('Warning: image was too large to display in format \"{}\"; '\n",
    "                 'trying jpeg instead.').format(format)\n",
    "            return imshow(a, format='jpeg')\n",
    "        else:\n",
    "            raise\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A. Generate One Sample Image\n",
    "\n",
    "Let's generate a sample BigGAN output image from category number 933, generated with a truncation value of 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = 933\n",
    "truncation=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a noise vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a noise vector, $z$ with size `dim_z` use the [`truncnorm.rvs()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.truncnorm.html) function. The authors suggest `(-2, 2)` for the bounds `a` and `b`, multiplied by the truncation value. Note: to work with tensorflow this vector needs to have dimensions `(1, dim_z)`. Set `random_state = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = truncation * truncnorm.rvs(-2, 2, size=(1, dim_z), random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a Histogram showing the distribution of values in your $z$ vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(z[0], 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a one-hot class selection vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class conditioning vector, $y$, selects the category of image we generate. To generate a \"one-hot\" class conditioning vector, we want an array of dimensions `(1, 1000)` that is uniformly zero, with the nth element (`category_index` above) set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((1,1000), dtype=np.float32)\n",
    "y[0, category_index]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify which element is non-zero (it should be `933`, our `category_index`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our TF session to generate an output\n",
    "\n",
    "Store our noise ($z$) and class ($y$) vectors as well as our truncation value (`truncation`) in feed dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {input_z: z, input_y: y, input_trunc: truncation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now run our tensorflow session to generate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sess.run(output, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What shape is our output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to grab the image data, and rescale the pixel range to display. (Rescale our values from `-1.0` to `1.0` to `0` to `256`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = results[0]\n",
    "image = np.clip(((image + 1) / 2.0) * 256, 0, 255)\n",
    "image = np.uint8(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap this image generation in a function for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(z, y, truncation):\n",
    "    feed_dict = {input_z: z, input_y: y, input_trunc: truncation}\n",
    "    results = sess.run(output, feed_dict=feed_dict)\n",
    "\n",
    "    image = results\n",
    "    image = np.clip(((image + 1) / 2.0) * 256, 0, 255)\n",
    "    image = np.uint8(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_images(z, y, truncation)\n",
    "imshow(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B. Generate a Set of Images\n",
    "\n",
    "Let's produce a set of 10 outputs at once! We need to create a batch of 10 noise vectors and 10 class labels/one hot vectors.\n",
    "\n",
    "(20 points total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "truncation = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `zs`, which will hold `num_samples` (10) truncated noise vectors (use `truncnorm.rvs` again with the same parameters as above).\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your result should have a shape of `(10, 128)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `ys`, which will hold `num_samples` (10) class selection/conditioning vectors. Use the same `category_index` as above.\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your result should have a shape of `(10, 1000)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `generate_image()` function above to calculate your results \n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your results should have shape `(10, 256, 256, 3)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use imshow to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theres a trick with `np.concatenate()` that will let us join all the images into a horizontal image, you will use this later on in the exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.concatenate(results, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore different values for `truncation` between 0.02 and 1.0. What is the effect of truncation on the outputs? (You can also consult the BigGAN paper to figure this out)\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C. Breeding Two Classes\n",
    "\n",
    "This section will show you how a weighted sum of class vectors results in a intermixed/combined output image. You will use the same noise vector (`z`) from above, but do a weighted sum of two different class conditioning vectors (`y_A` and `y_B`).\n",
    "\n",
    "(15 points total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation = 0.4\n",
    "weight = 0.5\n",
    "category_A = 207 # golden retriever\n",
    "category_B = 8 # hen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a noise vector $z$ using your method from above. Use the same parameters for `random_state` as well as `a` and `b`.\n",
    "\n",
    "(3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate two class conditioning vectors `y_A` and `y_B`, one hot encoding `category_A` and `category_B` above.\n",
    "\n",
    "(6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new class vector (`y_new`) that creates a weighted combination of `y_A` and `y_B` using `weight`.\n",
    "\n",
    "(3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the session to generate the output and display it.\n",
    "\n",
    "(3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D. Interpolation\n",
    "\n",
    "Now we will do a linear interpolation between these two classes of output and generate a number of intermediate transformation steps (`num_interps`).\n",
    "\n",
    "(30 points total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interps = 10\n",
    "truncation = 0.8\n",
    "noise_seed = 0\n",
    "category_A = 207 # golden retriever\n",
    "category_B = 8 # hen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `z_A` and `y_A` for `category_A` using `noise_seed` for your `random_state`\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `z_B` and `y_B` for `category_B` (again, using `noise_seed` for your `random_state`)\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 10 samples smoothly interpolating between `category_A` and `category_B`, both the `y_A`,`y_B` vectors and `z_A`,`z_B` vectors.\n",
    "\n",
    "(15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `generate_images()` from above and the `np.concatenate()` trick to display the series of interpolations as a single wide image.\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1E. Class Inversion\n",
    "\n",
    "If a one-hot vector conditions the class generation, what is the opposite of a given class? Let's try inverting the class generation vector (eg. multiply by `-1.0`).\n",
    "\n",
    "(15 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate and display an image from category `603` using the parameters below.\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation = 0.2\n",
    "noise_seed = 0\n",
    "category_index = 603 # horse cart\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate a companion image using the same $z$ vector, but with the category vector ($y$) inverted (multiplied by `-1`), and display the result.\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you describe the resulting image? What does it show?\n",
    "\n",
    "(5 points, no wrong answers!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Extension\n",
    "\n",
    "Extend this exercise in some aspect. Possible extension include:\n",
    "- Explore the full set of image classes. Find some particularly interest classes and combinations of classes, and produce hybrid/mutant outputs. What if we combine multiple (3) class vectors? Do we see a result with attributes of all three inputs?\n",
    "- Identify multiple points of interest in latent space. Create an animation with some traversal of those distinct points of interest (you may use ImageIO to create a GIF, as in the DCGAN notebook).\n",
    "- Explore manipulations of the noise vector ($z$). For instance, one blog post suggests applying `np.sin()` to the $z$ vector with a fixed class conditioning alters the zoom of the generated image.\n",
    "- Try to upload a new image of one of the trained classes and \"recover\" a corresponding latent vector. See the reference below (https://arxiv.org/abs/1702.04782)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A. Code\n",
    "\n",
    "Write your code below with comments:\n",
    "\n",
    "(15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B. Discussion\n",
    "\n",
    "Describe your goals for the extension, your results, and how this could lead to an interesting generative art project:\n",
    "\n",
    "(1 paragraph, 10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```REPLACE THIS WITH YOUR DISCUSSION OF YOUR EXTENSION```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- Andrew Brock, Jeff Donahue, and Karen Simonyan. [Large Scale GAN Training for High Fidelity Natural Image Synthesis](https://arxiv.org/abs/1809.11096). arxiv:1809.11096, 2018.\n",
    "- https://twitter.com/quasimondo/status/1151819357988761601?lang=en\n",
    "- Precise Recovery of Latent Vectors from Generative Adversarial Networks (2017) https://arxiv.org/abs/1702.04782\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BigGAN Hands-On",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
